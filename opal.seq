import bio
import math
import random
import sys
from matrix import matrix, save, load

counter1 = 0
counter2 = 0

def ldpc(k: int, t: int, _m: int) -> matrix[int]:
    """
    Generateas a low density code matrix of 0's and 1's, then converts that to
    a matirx of corresponding kmer indices.

    k:      width of matrix / length of k-mer
    t:      number of 1's per row / row_weight
    _m:     minimum matrix height / number of hashes
    """

    if k % t != 0:
        raise ValueError(f"k: ({k}) must be a multiple of t: ({t})")

    m = (int(math.ceil(_m * 1.0 / (k / t)) + 1)) * (k // t)
    w = m * t // k

    H_basic = matrix[int]((m // w, k), 0)
    H = matrix[int]((m, k), 0)

    for i in range(m // w):
        for j in range(i * t, (i + 1) * t):
            H_basic[i, j] = 1
            H[i, j] = 1

    perm_idx = list(range(k))
    for p in range(w - 1):
        random.shuffle(perm_idx)
        for pi in perm_idx:
            idx1 = (m // w) + (p * H_basic.shape[0])
            idx2 = idx1 + H_basic.shape[0]
            H[idx1:idx2, :] = H_basic[:, perm_idx]

    output = matrix[int]((H.shape[0], t))
    for i in range(H.shape[0]):
        count = 0
        for j in range(H.shape[1]):
            if H[i, j] == 1:
                output[i, count] = j
                count += 1
    return output

def encode(labels: list[str]) -> list[int]:
    unique_labels = list[str]()
    for elem in labels:
        if elem not in unique_labels:
            unique_labels.append(elem)
    return [unique_labels.index(x) + 1 for x in labels]

@atomic
def get_label(input: seq, labels: list[int]) -> tuple[seq, int]:
    global counter1
    label = labels[counter1]
    counter1 += 1
    return (input, label)

def fragment(input: tuple[seq, int], length: int, coverage: float):
    sequence, label = input
    seq_len = len(sequence)
    assert seq_len >= length
    for _ in range(int((coverage * seq_len) // length)):
        pos = random.randint(0, seq_len - length - 1)
        yield (sequence[pos:pos + length], label)

def _gen_features(sequence: seq, indices: matrix[int], kmer_length):
    output = list[str]()
    for kmer in split(sequence, kmer_length, 1):
        for i in range(indices.shape[0]):
            curr = ''
            for j in range(indices.shape[1]):
                curr += str(sequence[indices[i, j]])
            output.append(curr + str(i))
    return output

def train_features(input: tuple[seq, int], indices: matrix[int],
                   kmer_length: int, reverse: bool) -> tuple[list[str], int]:
    sequence, label = input
    features = _gen_features(sequence, indices, kmer_length)
    if reverse:
        features.ext(_gen_features(~sequence, indices, kmer_length))
    return (features, label)

def predict_features(input: seq, indices: matrix[int],
                 kmer_length: int, reverse: bool) -> tuple[list[str], int]:
    return train_features((input, -1), indices, kmer_length, reverse)

def format_sample(input: tuple[list[str], int]) -> str:
    features = ' '.join(input[0])
    label = f'{input[1]} | ' if input[1] > 0 else '| '
    return label + features

@atomic
def store(input: str, output: array[str]):
    global counter2
    output[counter2] = input
    counter2 += 1

def train(infile: str, labelfile: str, ldpc_file: str, kmer_length: int,
          hash_width: int, num_hashes: int, coverage: float,
          fragment_length: int, save_ldpc: bool, reuse_ldpc: bool,
          shuffle: bool, reverse_complement: bool, num_epochs: int):

    global counter1, counter2
    indices = None
    if reuse_ldpc:
        indices = load(ldpc_file)
    else:
        indices = ldpc(kmer_length, hash_width, num_hashes)
        if save_ldpc:
            save(indices, ldpc_file)

    labels = list[str]()
    encoded_labels = list[int]()
    if labelfile != "":
        labels = [x.rstrip('\n') for x in open(labelfile, 'r').readlines()]
        encoded_labels = encode(labels)

    # slight overhead, but allows pipeline to be parallized
    num_reads = 0
    max_read = 0
    for read in bio.FASTA(infile, fai=False):
        num_reads += 1
        seq_len = len(read.seq)
        if seq_len > max_read:
            max_read = seq_len
    max_samples = int((num_reads * coverage * max_read) / fragment_length)

    for _ in range(num_epochs):
        counter1 = 0
        counter2 = 0
        output = array[str](max_samples)
        (bio.FASTA(infile, fai=False)
            |> seqs
            |> get_label(encoded_labels)
            |> fragment(fragment_length, coverage)
            ||> train_features(indices, kmer_length, reverse_complement)
            |> format_sample
            |> store(output))
        idx = list(range(counter2))
        if shuffle:
            random.shuffle(idx)
        for i in idx:
            print(output[i])

def predict(infile: str, ldpc_file: str, kmer_length: int,
            reverse_complement: bool):

    indices = load(ldpc_file)

    output = list[str]()
    (bio.FASTA(infile, fai=False)
        |> seqs
        |> predict_features(indices, kmer_length, reverse_complement)
        |> format_sample
        |> output.append)
    for elem in output:
        print(elem)
